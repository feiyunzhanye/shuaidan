# -*- coding: utf-8 -*-
"""
业务需求：对每行数据的content 进行分词处理，计算每个词在全文档出现的频率，记录每个词的频率和出现该词的数据id集合
[{'word': ,'rate': ,'ids':[] }]
@author: feiyun
"""
import pandas as pd
import jieba
import jieba.analyse
file_data_path = "data/onlineData2.csv"
#加载停用词
def stopwordslist(filepath):
    stopwords = [line.strip() for line in open(filepath, 'r', encoding='utf-8').readlines()]
    return stopwords

#实现中文分词
def wordsSplit(text):
    stopwords = stopwordslist('data/stop_words_ch.txt')
    datas = []
    data_no_stop = []
    #jieba_words = jieba.lcut(text)
    jieba_words = jieba.analyse.extract_tags(text, topK=20, withWeight=False)
    #print('text:', jieba_words)
    outstr = ''
    outarray= []#按数组输出
    for word in jieba_words:
        if word not in stopwords:
            if word != '\t':
                outstr += word
                outstr += " "
                outarray.append(word)
    datas.append(outstr)
    data_no_stop.append(' '.join(jieba_words))
    #return ' '.join(datas)
    return outarray

f = open(file_data_path,'r',encoding='utf-8')
df = pd.read_csv(f,encoding='utf-8')  # 读入数据
data_content = df.iloc[:, 2:3].values.astype(str)
data_date = df.iloc[:, 1:2].values.astype(str)
data_id = df.iloc[:, 0:1].values.astype(str)#读入id
#格式化数据前后台交互
results = []
words = {}
words_set = []

for content in data_content:
    word = wordsSplit(content[0])
    words_set.append(word)
    for w in word:
        if w in words.keys():
            words[w] = words[w]+1
        else:
            words[w] = 1
print(words)
for key in words.keys():
    result = {}
    ids = []
    for i in range(0,len(words_set)):
        if key in words_set[i]:
            ids.append(data_id[i][0])
    result['word'] = key
    result['rate'] = words[key]
    result['ids'] = ids
    print(result)
    results.append(result)
    #print(result)
print(results)
#排序
results.sort(key=lambda z:z["rate"],reverse=True)
print(results)
#总的关键词排序 [(),(),()]
words_sort = sorted(words.items(),key=lambda item:item[1])
words_sort_20 = words_sort[0:20]
#print(words_sort_20)
#文件写入
# dataf = pd.DataFrame({'id':data_id,'top_words':words_out,'content':data_content})
# dataf.to_csv('data/chuli_keywords_10000hao.csv',index=False)
